{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAN\n",
    "- Generative Adversarial Network\n",
    "- 생산적 적대 신경망"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(\"/Users/changmin.kim/Desktop/jupyterNotebook/Hands_on_Machine_Learning/dir/train_data.npy\")\n",
    "label = np.load(\"/Users/changmin.kim/Desktop/jupyterNotebook/Hands_on_Machine_Learning/dir/train_label.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameter\n",
    "\n",
    "total_epoch = 100\n",
    "batch_size = 100\n",
    "learning_rate = 0.0002\n",
    "n_hidden = 256\n",
    "n_input = 28*28\n",
    "n_noise = 128 # 생성자의 입력값으로 사용할 노이즈의 크기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_batch(batch_size,data):\n",
    "    result = np.arange(0,len(data))\n",
    "    np.random.shuffle(result)\n",
    "    result = result[:100]\n",
    "    dataset = [data[i] for i in result]\n",
    "    return np.array(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalization(data):\n",
    "    return (data-np.min(data))/(np.max(data)-np.min(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardization(data):\n",
    "    mean = np.mean(data)\n",
    "    std = np.std(data)\n",
    "    datas = (data-np.mean(data))/np.std(data)\n",
    "    return datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32,[None,n_input])\n",
    "Z = tf.placeholder(tf.float32,[None,n_noise])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_W1 = tf.Variable(tf.random_normal([n_noise,n_hidden],stddev=0.01))\n",
    "G_b1 = tf.Variable(tf.zeros([n_hidden]))\n",
    "\n",
    "G_W2 = tf.Variable(tf.random_normal([n_hidden,n_input],stddev=0.01))\n",
    "G_b2 = tf.Variable(tf.zeros([n_input]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_W1 = tf.Variable(tf.random_normal([n_input,n_hidden],stddev=0.01))\n",
    "D_b1 = tf.Variable(tf.zeros([n_hidden]))\n",
    "\n",
    "D_W2 = tf.Variable(tf.random_normal([n_hidden,1],stddev=0.01))\n",
    "D_b2 = tf.Variable(tf.zeros([1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(noise_z):\n",
    "    hidden = tf.nn.relu(tf.matmul(noise_z, G_W1) + G_b1)\n",
    "    output = tf.nn.sigmoid(tf.matmul(hidden, G_W2) + G_b2)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator(inputs):\n",
    "    hidden = tf.nn.relu(tf.matmul(inputs,D_W1)+D_b1)\n",
    "    output = tf.sigmoid(tf.matmul(hidden,D_W2)+D_b2)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_noise(batch_size,n_noise):\n",
    "    return np.random.normal(size=(batch_size,n_noise)).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = generator(Z)\n",
    "D_gene = discriminator(G)\n",
    "D_real = discriminator(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_D = tf.reduce_mean(tf.log(D_real)+tf.log(1-D_gene))\n",
    "loss_G = tf.reduce_mean(tf.log(D_gene))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_var_list = [D_W1,D_b1,D_W2,D_b2]\n",
    "G_var_list = [G_W1,G_b1,G_W2,G_b2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_D = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(-loss_D,var_list=D_var_list)\n",
    "train_G = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(-loss_G,var_list=G_var_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "total_batch = int(len(data)/batch_size)\n",
    "data = normalization(data)\n",
    "loss_val_D, loss_val_G =0,0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0.   0.   0.   0.   0.   0.   0.   0.   0.   6.   0.   0.   3.   0.\n",
      "   0.   8.   5.   0.   3.  12.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   3.   4.   1.  10.\n",
      "   8.   0.   1.   0.   0.   0.   0.   0.   8.  10.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   2.   0.   0.   9.   0.\n",
      "   0.   7.   0.  14.  18.   9.   5.   1.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   9.   7.   0.   8.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.  12.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.  13.   0.   0.   2.  74. 186.\n",
      " 255. 252.  23.  16.   0.   0.  15.   9.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   9.  17.  75. 239. 252.\n",
      " 234. 255.  26.  84.  78.   6.   0.   9.  17.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   8.   0. 124. 243. 255. 234.\n",
      " 255. 255. 214. 255. 244. 115.   4.   0.  10.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0. 114. 244. 255. 230. 114.\n",
      " 111. 162. 255. 242. 253. 231. 120.   8.   0.   6.   0.   0.   0.   0.\n",
      "   1.   0.   0.   0.   0.   3.  21.   0.  94. 240. 246. 221.  89.   0.\n",
      "  15.   0. 218. 219. 255. 248. 211.   9.   0.   5.   0.   0.   0.   0.\n",
      "   6.   8.   3.   9.   0.   0.   0.  31. 209. 245. 242.  76.  12.   9.\n",
      "   0.   6.  73.  82. 228. 236. 238.   9.   2.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   1.  12.   0. 166. 255. 238. 133.   0.   0.   0.\n",
      "   0.   0.   0.   0. 125. 255. 251. 116.  10.   0.   0.   0.   0.   0.\n",
      "   4.   5.   1.   0.   0.   3.  52. 245. 248. 176.   2.   2.   7.   0.\n",
      "  12.   0.   1.   0.  31. 255. 244. 218.   6.   0.   0.   0.   0.   0.\n",
      "   0.   2.   8.   5.   0.   0. 121. 249. 255.  82.   0.   5.   0.   6.\n",
      "   0.   3.   6.   1.   6. 203. 245. 222.   9.   1.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.  16. 206. 255. 215.  29.   4.   0.   0.   1.\n",
      "   0.   0.   0.   0.   0. 180. 255. 237.  43.   4.   0.   0.   0.   0.\n",
      "   9.  14.   0.   0.   0.  53. 244. 255. 116.  14.   0.   4.   3.   0.\n",
      "  14.   0.   2.   1.   0. 195. 252. 255.  92.   2.   0.   0.   0.   0.\n",
      "   0.   6.   0.   7.  12.  97. 255. 253.  51.   0.   0.   9.   0.   7.\n",
      "   0.   4.   4.   0.   9. 191. 237. 247. 122.   0.   0.   0.   0.   0.\n",
      "  10.   0.   0.   0.   0. 113. 255. 251.  49.   0.  16.   0.   0.  13.\n",
      "   0.   7.   0.   7.   0. 200. 251. 243.  64.   8.   0.   0.   0.   0.\n",
      "   0.   5.   0.   0.  12.  57. 238. 255.  52.   4.   0.   0.   0.   0.\n",
      "  16.   0.   8.   1.  52. 230. 246. 229.   0.   0.   0.   0.   0.   0.\n",
      "   0.   5.   0.   0.   3.   3. 230. 244.  56.   0.   9.  23.   0.   1.\n",
      "   6.   0.   0.  24. 183. 255. 250. 131.   0.  29.   0.   0.   0.   0.\n",
      "   7.   0.   3.   2.   0.   1. 232. 245. 157.  28.   0.   0.   0.  16.\n",
      "   0.   0.  36. 120. 239. 252. 209.  26.   0.   0.   0.   0.   0.   0.\n",
      "   4.   0.   2.   5.   0.  19. 182. 255. 253. 168.  22.  14.  16.   0.\n",
      "   8.  12. 170. 255. 255. 239. 121.   9.   6.   0.   0.   0.   0.   0.\n",
      "   0.   5.   0.   1.   5.   7.  71. 235. 245. 251. 176. 164. 150. 106.\n",
      " 157. 206. 255. 255. 217. 111.  10.   0.   0.  12.   0.   0.   0.   0.\n",
      "   1.   2.   2.   1.   0.   0.   1. 105. 224. 251. 249. 249. 255. 255.\n",
      " 254. 245. 255. 159. 110.   1.   0.   7.   0.   0.   0.   0.   0.   0.\n",
      "   7.   0.   6.   8.   0.   6.  11.   0.   0. 100. 146. 236. 255. 245.\n",
      " 249. 130.  72.  12.   0.   0.   0.  15.   0.   5.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n"
     ]
    }
   ],
   "source": [
    "print(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0000 D loss: nan G loss: nan\n",
      "Epoch: 0001 D loss: nan G loss: nan\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-3e950d256e57>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0mbatch_xs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0mnoise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_noise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_noise\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-6749eceb4626>\u001b[0m in \u001b[0;36mrandom_batch\u001b[0;34m(batch_size, data)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrandom_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/changmin.kim/anaconda3/lib/python3.7/site-packages/matplotlib/image.py:397: UserWarning: Warning: converting a masked element to nan.\n",
      "  dv = (np.float64(self.norm.vmax) -\n",
      "/Users/changmin.kim/anaconda3/lib/python3.7/site-packages/matplotlib/image.py:398: UserWarning: Warning: converting a masked element to nan.\n",
      "  np.float64(self.norm.vmin))\n",
      "/Users/changmin.kim/anaconda3/lib/python3.7/site-packages/matplotlib/image.py:405: UserWarning: Warning: converting a masked element to nan.\n",
      "  a_min = np.float64(newmin)\n",
      "/Users/changmin.kim/anaconda3/lib/python3.7/site-packages/matplotlib/image.py:410: UserWarning: Warning: converting a masked element to nan.\n",
      "  a_max = np.float64(newmax)\n",
      "/Users/changmin.kim/anaconda3/lib/python3.7/site-packages/matplotlib/colors.py:885: UserWarning: Warning: converting a masked element to nan.\n",
      "  dtype = np.min_scalar_type(value)\n",
      "/Users/changmin.kim/anaconda3/lib/python3.7/site-packages/numpy/ma/core.py:713: UserWarning: Warning: converting a masked element to nan.\n",
      "  data = np.array(a, copy=False, subok=subok)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjwAAAA9CAYAAACpzLMWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAABKUlEQVR4nO3WQQ0AIBDAMMC/50MFIVlaBXtuz8wCACg7vwMAAF4zPABAnuEBAPIMDwCQZ3gAgDzDAwDkGR4AIM/wAAB5hgcAyDM8AECe4QEA8gwPAJBneACAPMMDAOQZHgAgz/AAAHmGBwDIMzwAQJ7hAQDyDA8AkGd4AIA8wwMA5BkeACDP8AAAeYYHAMgzPABAnuEBAPIMDwCQZ3gAgDzDAwDkGR4AIM/wAAB5hgcAyDM8AECe4QEA8gwPAJBneACAPMMDAOQZHgAgz/AAAHmGBwDIMzwAQJ7hAQDyDA8AkGd4AIA8wwMA5BkeACDP8AAAeYYHAMgzPABAnuEBAPIMDwCQZ3gAgDzDAwDkGR4AIM/wAAB5hgcAyDM8AECe4QEA8gwPAJB3AVxjA3d1+eKUAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x72 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for epoch in range(total_epoch):\n",
    "    for i in range(total_batch):\n",
    "        batch_xs = random_batch(batch_size,data)\n",
    "        noise = get_noise(batch_size, n_noise)\n",
    "\n",
    "        # 판별기와 생성기 신경망을 각각 학습시킵니다.\n",
    "        _, loss_val_D = sess.run([train_D, loss_D],\n",
    "                                 feed_dict={X: batch_xs, Z: noise})\n",
    "        _, loss_val_G = sess.run([train_G, loss_G],\n",
    "                                 feed_dict={Z: noise})\n",
    "\n",
    "    print('Epoch:', '%04d' % epoch,\n",
    "          'D loss: {:.4}'.format(loss_val_D),\n",
    "          'G loss: {:.4}'.format(loss_val_G))\n",
    "    \n",
    "    if epoch == 0 or (epoch + 1) % 10 == 0:\n",
    "        sample_size = 10\n",
    "        noise = get_noise(sample_size, n_noise)\n",
    "        samples = sess.run(G, feed_dict={Z: noise})\n",
    "\n",
    "        fig, ax = plt.subplots(1, sample_size, figsize=(sample_size, 1))\n",
    "\n",
    "        for i in range(sample_size):\n",
    "            ax[i].set_axis_off()\n",
    "            ax[i].imshow(np.reshape(samples[i], (28, 28)))\n",
    "\n",
    "\n",
    "print('최적화 완료!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 256)\n",
      "(256, 1)\n",
      "1.6178625393761602e-67\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan]], dtype=float32)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(np.shape(D_W1))\n",
    "print(np.shape(D_W2))\n",
    "print(0.000000000000000000000000000000000131320011313*0.000000000000000000000000000000001232)\n",
    "tf.nn.sigmoid(np.mean(sess.run(G_W2)[0]*data[0]))\n",
    "print(sess.run((D_W1[200])))\n",
    "sess.run(tf.matmul(data[:1],D_W1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "nan\n",
      "inf\n",
      "nan\n"
     ]
    }
   ],
   "source": [
    "print(1/np.inf)\n",
    "print(np.inf/np.inf)\n",
    "print(1.e1000)\n",
    "print(1.e1000/1.e1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NaN =  NaN을 포함하는 산술 연산을 수행하는 경우와 마찬가지로, 0/0 및 inf/inf와 같은 표현식은 NaN을 반환<br>\n",
    "inf = 무한대는 0으로 나누기(Division By Zero)나 오버플로와 같은 연산에서 초래되며, 이와 같은 연산은 기존의 부동소수점 값으로 나타내기에는 너무 큰 값을 발생"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1/np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-inf"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1-1.e1000/0.0000000000001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "inf"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
